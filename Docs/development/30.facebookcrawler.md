After successful cloning of the project,
 
Step 1: Navigate to "Backend" folder and open FacebookCrawler.py file in Visual Studio code

Step 2: Open terminal in Visual Studio Code and install the required packages with the following commands:
1. pip install selenium
2. pip install python-dotenv
3. pip install mysql-connector-python (To connect to local db)
 
Step 3: Change the path to your ChromeDriver path on Line 65 in FacebookCrawler.py file
For example: 
In this line,     
service=ChromeService(executable_path="D:\\UGH Project\\UGH-Backend-Docker-Frontend\\chromedriver.exe"), 
Replace "D:\\UGH Project\\UGH-Backend-Docker-Frontend\\chromedriver.exe" with your ChromeDriver path
 
(**Running the ChromeDriver executable file**)
Step 4: Navigate outside the "Backend" folder in File explorer where you will find the ChromeDriver.exe file (Ensure the version of ChromeDriver should be 125.0.6422.60). Double click to run the ChromeDriver.
 
(**Storing Images from Database(In Blob) to Local machine(in .jpg)**)
Step 5: Create a folder in your machine to store images from Database which will be posted on the Facebook closed group,

Step 6: Copy the path of the created folder and paste it on Line 97 in FacebookCrawler.py file.
For example:
In this line, 
file_path = r"C:\Users\Downloads\fb_upload.jpg"
Replace "C:\Users\Downloads\fb_upload.jpg" with your image folder path

As soon as an offer is posted on Platform, the scheduler will hit after every 10 minutes which will get newly added offers from Database and post them on the Facebook closed group!



-----------------------------------------------------------------------------------------------------



Navigieren Sie nach erfolgreichem Klonen zum Ordner "Backend" und öffnen Sie die Datei "FacebookCrawler.py" im Visual Studio-Code
 
Öffnen Sie das Terminal in Visual Studio Code und installieren Sie die erforderlichen Pakete mit den folgenden Befehlen:

1. pip install selenium
2. pip install python-dotenv
3. pip install mysql-connector-python (Um eine Verbindung zur lokalen Datenbank herzustellen)
 
Navigieren Sie im Datei-Explorer außerhalb des Ordners "Backend" , wo Sie die Datei ChromeDriver.exe finden (stellen Sie sicher, dass die Version von ChromeDriver 125.0.6422.60 sein sollte). Doppelklicken Sie, um den ChromeDriver auszuführen. 
Ändern Sie den Pfad zu Ihrem ChromeDriver-Pfad in Zeile 65 in der Datei FacebookCrawler.py
Zum Beispiel: 
In dieser Zeile     
service=ChromeService(executable_path="D:\\UGH Project\\UGH-Backend-Docker-Frontend\\chromedriver.exe"), 
Ersetzen Sie "D:\\UGH Project\\UGH-Backend-Docker-Frontend\\chromedriver.exe" durch Ihren ChromeDriver-Pfad
 
 
Erstellen Sie auf Ihrem Computer einen Ordner zum Speichern von Bildern aus der Datenbank, die in der geschlossenen Facebook-Gruppe veröffentlicht werden. 
Kopieren Sie den Pfad des erstellten Ordners und fügen Sie ihn in Zeile 97 in der Datei FacebookCrawler.py ein.
Zum Beispiel:
In dieser Zeile, 
file_path = r"C:\Benutzer\Downloads\fb_upload.jpg" mit Ihrem Bildordnerpfad

Sobald ein Angebot auf der Plattform veröffentlicht wird, greift der Planer alle 10 Minuten zu, wodurch neu hinzugefügte Angebote aus der Datenbank abgerufen und in der geschlossenen Facebook-Gruppe veröffentlicht werden!
